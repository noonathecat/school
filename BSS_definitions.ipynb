{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "0szFUF9Rcf03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMHUz9QMfGxE"
      },
      "outputs": [],
      "source": [
        "def my_reg_model_rsq (Xmatrix, y, feature_set):\n",
        "\n",
        "    \"\"\"\n",
        "    Xmatrix and y are array-like objects.\n",
        "    They could be arrays or data frames.\n",
        "    Xmatrix is the matrix with all the predictors.\n",
        "    The predictors must all numeric (we must convert categorical ones into dummies).\n",
        "    y is the array/Series with the outcome variable values.\n",
        "    The feature_set must be a list with the names of the predictors to incude in the equation.\n",
        "\n",
        "    The output is a tuple where:\n",
        "    First element is the feature set list (a nice list of strings)\n",
        "    Second element is the R sq\n",
        "    \"\"\"\n",
        "\n",
        "    X = sm.add_constant(Xmatrix[feature_set])\n",
        "    reg_model= sm.OLS(y,X).fit()\n",
        "\n",
        "    return(feature_set, reg_model.rsquared)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_best_reg_size_k (X, y, size):\n",
        "\n",
        "    \"\"\"\n",
        "    X is a dataframe, where each column is a predictor.\n",
        "    y is the array/Series with the values of Y.\n",
        "    If size= k, it means you want to find out the best equation with k predictors.\n",
        "\n",
        "    This function returns a tuple with two elements: the name of the best predictor(s) of size k\n",
        "    and the r sq for the equation with this (these) predictor(s)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # List to store all combinations of predictor names of size k\n",
        "    combinations_k_predictors= list (combinations(list(X.columns), size))\n",
        "\n",
        "    # Dictionaty to store the predictor names and the R sq for the equation with these predictors\n",
        "    r_sq_size_k_dic={}\n",
        "\n",
        "    # Calculate R-squared for model of size k\n",
        "    for predictors_iteration in combinations_k_predictors:\n",
        "        predictor_names, rsq_value = my_reg_model_rsq(X, y, list(predictors_iteration))\n",
        "        r_sq_size_k_dic[tuple(predictor_names)] = rsq_value\n",
        "\n",
        "    # Find the combination with the max R-squared\n",
        "    best_predictors = max(r_sq_size_k_dic, key=r_sq_size_k_dic.get)\n",
        "    best_rsq = np.round(r_sq_size_k_dic[best_predictors], 4)\n",
        "\n",
        "    # output as a tuple\n",
        "    return best_predictors, best_rsq"
      ],
      "metadata": {
        "id": "KXWLV9pWfVqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_best_subset_selection(X, y, threshold):\n",
        "\n",
        "    \"\"\"\n",
        "    X is a dataframe where each column is a predictor.\n",
        "    y is the array/Series with the values of Y.\n",
        "    threshold is the percent increase threshold to determine the best subset of predictors.\n",
        "    threshold is to be entered as a percent (e.g., 10 instead of 0.1)\n",
        "\n",
        "    This function finds the best subset of predictors based on adjusted R-squared values.\n",
        "    \"\"\"\n",
        "\n",
        "    # Array to store adjusted R-squared values. As many values as columns in X\n",
        "    adj_squared_values = np.empty(X.shape[1])\n",
        "\n",
        "    # Loop through different sizes of predictor subsets (from 1 to total number of predictors)\n",
        "    for num_predictors in range(1, X.shape[1] + 1):\n",
        "        # Use my_best_reg_size_k() to get best model of size k\n",
        "        best_model_k = my_best_reg_size_k(X, y, num_predictors)\n",
        "\n",
        "        best_rsq_k = best_model_k[1]\n",
        "\n",
        "        # Calculate Adjusted R-squared and convert it to a %\n",
        "        adj_rsq_k = (1 - ((1 - best_rsq_k) * (X.shape[0] - 1)) / (X.shape[0] - 1 - num_predictors)) * 100\n",
        "\n",
        "        adj_squared_values[num_predictors - 1] = adj_rsq_k\n",
        "\n",
        "\n",
        "    # The code left the for loop at this stage\n",
        "\n",
        "    # Compute the percentage change in adjusted R-squared values and convert it into a %\n",
        "    percent_change_adj_rsq = ((adj_squared_values[1:] - adj_squared_values[0:-1]) / adj_squared_values[0:-1])*100\n",
        "\n",
        "    # print (percent_change_adj_rsq) No needed this print(). I used it when writing function to confirm\n",
        "\n",
        "    #  Find out when this increase is >= threshold. 'meets_threshold' is a Boolean array\n",
        "    meets_threshold= percent_change_adj_rsq >= threshold\n",
        "\n",
        "    # print (above_threshold) No needed this print(). I used it when writing function to confirm\n",
        "\n",
        "    # Find the index where the percent increase falls below the threshold\n",
        "    best_index = np.min(np.where(meets_threshold == False))\n",
        "\n",
        "    # Get the best predictors and adjusted R-squared for the optimal model\n",
        "    best_predictors = my_best_reg_size_k(X, y, best_index + 1)[0]\n",
        "    best_adj_rsq = np.round(adj_squared_values[best_index], 2)\n",
        "\n",
        "    print ('Using adjusted r squared as a reference metric and a minimum percent increase threshold of', threshold,'%, ', 'the best equation is the one with these predictors:', best_predictors)\n",
        "    print (' The adjusted r squared of this equation is', best_adj_rsq, \"%\")\n"
      ],
      "metadata": {
        "id": "wKJo7JSnfYVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_best_subset_selection_cv(X, y, folds):\n",
        "\n",
        "    \"\"\"\n",
        "    Apply Best Subset Selection (BSS) method based on cross-validation to find the best subset of predictors.\n",
        "\n",
        "    X is a dataframe where each column is a predictor.\n",
        "    y is the array/Series with the values of Y.\n",
        "    folds is the number of cross-validation folds.\n",
        "\n",
        "    Function outputs:\n",
        "    It returns a data frame with the mean cross-validation MSE for each subset of predictors.\n",
        "    It also prints the CV scores for each iteration performed for each subset of predictors.\n",
        "    \"\"\"\n",
        "\n",
        "    cv_object = KFold(n_splits= folds, shuffle=True, random_state=1)\n",
        "\n",
        "    # Empty data frame to store the CV results of all iterations (all subsets of predictors under comparison)\n",
        "    out_df = pd.DataFrame(columns=['Predictors', 'Mean_CV_MSE'])\n",
        "\n",
        "    # Iterate through subsets of predictors from size 1 to the total number of predictors\n",
        "    for num_predictors in range(1, X.shape[1] + 1):\n",
        "        # Use my_best_reg_size_k() to get the best model of size k and its corresponding R-squared\n",
        "        best_model_k = my_best_reg_size_k(X, y, num_predictors)\n",
        "        predictor_names = best_model_k[0]\n",
        "\n",
        "        # Convert 'predictor_names' from a tuple to a list\n",
        "        predictor_names_list = list(predictor_names)\n",
        "\n",
        "        # Perform cross-validation and compute mean MSE\n",
        "        cv_values = -cross_val_score(LinearRegression(), X[predictor_names_list], y,\n",
        "                                     scoring='neg_mean_squared_error', cv= cv_object)\n",
        "        # Compute average CV error\n",
        "        mean_cv_mse = np.round(cv_values.mean(), 4)\n",
        "\n",
        "        # Create a new row in the df_iteration data frame with the current iteration results\n",
        "        df_iteration = pd.DataFrame({'Predictors': [predictor_names_list],'Mean_CV_MSE': [mean_cv_mse]})\n",
        "\n",
        "        # Concatenate the current iteration's results with the overall results\n",
        "\n",
        "        out_df = pd.concat([out_df, df_iteration], ignore_index=True)\n",
        "\n",
        "        # Print results for the current cv iteration\n",
        "        print(\"Cross-validation results for predictors:\", predictor_names_list)\n",
        "        print(\"Cross-validation MSE values:\", cv_values)\n",
        "        print(\"Mean cross-validation MSE:\", mean_cv_mse)\n",
        "        print()\n",
        "\n",
        "    # Loop execution is done at this stage\n",
        "\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "CoCwg5Y023l7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}